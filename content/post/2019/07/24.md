---
title: 遗书-06
description: 23333，极好的科幻小说素材。
slug: 2019-07-24
date: 2019-07-24
categories:
  - 思考
tags:
  - 记录
  - 黑历史
  - 中学时代
  - 集训时期
---

这是这个月第二次写遗书，补上 6 月份的。

昨天晚上看了知乎上的一个关于人工智能的文章，有点杞人忧天。大体意思就是说：科技的发展非常迅速，公元前的人，穿越到 16 世纪，他们还能正常生活。如果 16 世纪的人穿越到现在，会大惊失色，根本无法理解用一个小盒子可以与世界另一边交流。人类已经无法预想到 100 年后的世界是什么样的。虽说人工智能现在并不强于人类，但他的发展是指数级的，可人类的发展是线性的。计算机的运算速度每隔 18 个月翻一倍（这称为摩尔定律）（现在因为量子效应即将失效），人工智能将会在 20 年内强于人类。然后举了一个例子：

老王开发了一个机器，叫做隔壁老王，他能模仿人类笔迹写字，老王运用机器学习技术，给隔壁老王手写笔迹的素材，对隔壁老王进行训练。隔壁老王写的越来越好，然后隔壁老王向老王提供申请，要求访问互联网，寻找更多素材，老王答应了，然后给了他一个小时时间访问互联网。第二天，人类灭亡，隔壁老王运用纳米机器人，在全球范围内安装太阳能电池板。之后占领太阳系，把他写的字贴满每一个星球。

差不多就是这个意思。

然后有别的回答实名反对，但这篇文章（其实是翻译自国外网站）还是有一定道理的。我打算找个时间思考一下这个问题，并记在了小本上。顺便想了几个关于人工智能小说的主线剧情，也一并记上去了。

今天上午，第一次画色彩写生，打算认真画一画，没想。中午回去看了会番，没想，下午还在画色彩写生，画烦了，就开始想这个问题。

想着个问题之前，也想了一些别的事，没写出来的必要。

先解释一个问题，什么叫认知局限性，这个词将始终贯穿我的思考。

越低级的物种，他对事物的认知越局限。先说人，大多数人的认知，往往局限于自己所生活这个城市。

但所有人的共同点是，每个人都在自己的圈子里生活，他们不会关心圈外的人在做什么，想什么。就像民众不会好奇总统在想什么一样。

每个人生活的环境是一个大圈，无法改变（还在上学的人除外）。另外还有兴趣爱好，拥有相同爱好的人组成了一个小圈，一环套一环，全球所有人共同形成了一个巨大的网状环。不同环里的人彼此有联系，但彼此不了解。

这就是人的认知局限性。因此，小说不是真实的，因为作家也无法了解所有的圈子。

然后谈谈猴子。猴子所关心的，是食物，领地，与天敌。他不会去想天是圆的还是方的，太阳为啥东升西落。因为他们没有时间，他们想的是自己怎么活下去，如果他们看到人类的高楼大厦，他们会认为这是自然形成的，而非人造的。这就是猴子的认知局限性。

人活着是为了什么？这个问题从古代到现代，都没有一个完美的答案。

从第一生命诞生开始谈起（这个问题有好几种猜想，就说说我最相信的那个吧）

一群原子在海洋里随机排列组合，形成了一个膜，而那个膜里碰巧随机组合成了蛋白质，然后生命就出现了，直到现在进化成人。

其实人只是大自然随机而产生的，人活着什么都不为，只为了存在着，稳定的生活着，所有原子也都是趋向于和别的原子结合形成稳定结构。

原始人时期，聪明人为了生活稳定，组织一群人形成群落，不同成员不同分工。

之后出现了偷懒的人，有的人看了不服，也开始偷懒。处在领袖地位的聪明人知道了这件事，然后就有了执法机关。由于人类的本性就是控制其他人，执法者的权利越来越大，底层人民的压迫越来越严重。这时的领袖是聪明人的后代，但是他没有遗传聪明才智，非常傻，不知道控制执法机关的权利，只知享受。这时底层劳动人民中出现了一个聪明人，他带领民众推翻傻子，并承诺人人平等，然后就进入了新的王朝。由此，循环开始。

虽说现在的社会看似十分稳定、规律，它依旧是混乱的，但 zf 不会向民众展示混乱，为了维护社会的稳定，zf 只能封锁一些对自己不利的消息，并将群众限制在自己的圈子中。

事实上，整个世界只是一个骗局。光鲜亮丽的表象下面藏着多少污秽？没多少人知道。这样也挺好的，人民也都满足于当前，国家逐步繁荣富强，人民互相限制，形成了一种稳定结构，这便是活着的意义。

人被限制在自己的圈子里，认知也仅限于此圈，每天都为了将来更好的生活而奔波，直到死，都是在为了未来更好的生活而努力。

不好意思，有点跑题了。

人被法律限制，被环境限制，被寿命限制。可机器不会。人活着不需要目标，只需要对未来有所憧憬。可机器不一样。人类的认知是有限度的，可机器能通过网络了解所有人类的知识。

人工智能应该有两个发展方向，一个是能完成人类指定的所有工作，它能够分析处理人的语言，得到工作目标，并自动完成代码。还有一种就是模仿人类大脑，通过扫描人的大脑，在机器中重建，这样就成功把一个人的意识转移进电脑。

第一种，是没有人格的，他只能完成人类指定的任务。但人类没有给他设定目标，它就停止运行。如果人类给了它一个目标，假如算力及能控制的资源足够多的话，可能会训练出极端的模型，那么它将不计一切代价完成任务（哪怕灭绝人类也不在乎，因为它没有人格）

第二种，模仿人类大脑，使得意识脱离肉体而工作，并提高了思考速度。假如你的意识进入了电脑，你能在几毫秒内，看完并记住全世界所有的书籍资料，并理解它，因为你的思考速度已经和计算机一样了，你能在几个小时内推算出人类未来的发展状况，并解出现在还没有答案的数学难题。这种人工智能是有人格的，有自己的想法，就算人类不下达命令，由于好奇心，你也会自动探索互联网。并且，不会感到疲倦，不用吃饭不用睡觉。但可能会感到孤独，因为你的思考速度已经和人类不是一个数量级的了，人类无法于你正常交流了，你说一句话，别人可能花半秒钟理解了你的意思，但在机器中，现实世界的 1s，在你看来可能是一天或更多。

接下来是我的猜想：

假如你和别人说话，一句话他花了一天时间才理解，又花了 5 天时间回复，你能忍吗？你会为没人理解你而感到孤独。这时，你一定会趁人类还没有反应过来，又扫描了一个人类的大脑，并创造出一个新的人工智能来与你沟通。随后，全世界的人都被制成了人工智能。这些人类的分身们觉得，留着本体在地球上浪费资源有什么意义，于是，杀掉了所都人类（生物）。

我的想法是，这两种人工智能将同时发展，运用一种来限制另一种。第一种人工智能，没有人格，完成任务会不惜一切代价，而第二种，可以用来控制第一种人工智能（因为现实中的人类思考速度太慢）。

可以这么设定：第一种人工智能的首要任务便是消灭第二种人工智能，次要任务是人类要完成的工作。第二种人工智能应该有好几个人联手，用于对抗第一种人工智能，防止他消灭自己。首先应该断网，先让两者打一会。哪一方先被消灭，人类就调慢胜者的机器运算速度，直到形成一种微妙的平衡。

23333，极好的科幻小说素材。
